{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import albumentations\n",
    "import torch.optim as optim\n",
    "from albumentations.pytorch import ToTensorV2, ToTensor\n",
    "\n",
    "from C2C.models.resnet import *\n",
    "from C2C import train\n",
    "from C2C.loss import KLDLoss\n",
    "from C2C.eval_model import *\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "torch.cuda.manual_seed(12)\n",
    "np.random.seed(12)\n",
    "random.seed(12)\n",
    "\n",
    "torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data CSV\n",
    "\n",
    "- CSV file must contain following columns:\n",
    "    - path - location of each patch\n",
    "    - wsi - Unique identifier for WSI\n",
    "    - label - Label of WSI (Binary 0 or 1)\n",
    "    - is_valid - If WSI part of validation cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = '/workspace/icml_rebuttual/patch_data.csv'\n",
    "df = pd.read_csv(CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>wsi</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./patch_dataset_4096_512/65bf2cc6f9ed1eed86b8e...</td>\n",
       "      <td>65bf2cc6f9ed1eed86b8e7a908efe834</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./patch_dataset_4096_512/65bf2cc6f9ed1eed86b8e...</td>\n",
       "      <td>65bf2cc6f9ed1eed86b8e7a908efe834</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./patch_dataset_4096_512/65bf2cc6f9ed1eed86b8e...</td>\n",
       "      <td>65bf2cc6f9ed1eed86b8e7a908efe834</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./patch_dataset_4096_512/65bf2cc6f9ed1eed86b8e...</td>\n",
       "      <td>65bf2cc6f9ed1eed86b8e7a908efe834</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./patch_dataset_4096_512/65bf2cc6f9ed1eed86b8e...</td>\n",
       "      <td>65bf2cc6f9ed1eed86b8e7a908efe834</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  \\\n",
       "0  ./patch_dataset_4096_512/65bf2cc6f9ed1eed86b8e...   \n",
       "1  ./patch_dataset_4096_512/65bf2cc6f9ed1eed86b8e...   \n",
       "2  ./patch_dataset_4096_512/65bf2cc6f9ed1eed86b8e...   \n",
       "3  ./patch_dataset_4096_512/65bf2cc6f9ed1eed86b8e...   \n",
       "4  ./patch_dataset_4096_512/65bf2cc6f9ed1eed86b8e...   \n",
       "\n",
       "                                wsi  is_valid  label  \n",
       "0  65bf2cc6f9ed1eed86b8e7a908efe834     False      2  \n",
       "1  65bf2cc6f9ed1eed86b8e7a908efe834     False      2  \n",
       "2  65bf2cc6f9ed1eed86b8e7a908efe834     False      2  \n",
       "3  65bf2cc6f9ed1eed86b8e7a908efe834     False      2  \n",
       "4  65bf2cc6f9ed1eed86b8e7a908efe834     False      2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py117/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/py117/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Initialize Model\n",
    "model_ft = WSIClassifier(6, bn_track_running_stats=True)\n",
    "model_ft = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss, Optimizer, and Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Transforms\n",
    "data_transforms = albumentations.Compose([\n",
    "    ToTensor()\n",
    "    ])    \n",
    "\n",
    "# Cross Entropy Loss \n",
    "criterion_ce = nn.CrossEntropyLoss()\n",
    "criterion_kld = KLDLoss()\n",
    "criterion_dic = {'CE': criterion_ce, 'KLD': criterion_kld}\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adam(model_ft.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/C2C/C2C/train.py:31: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  valid_images = dict(df.loc[df['is_valid']==1].groupby('wsi')['path'].apply(list))\n",
      "/workspace/C2C/C2C/train.py:33: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  valid_images_label = dict(df.loc[df['is_valid']==1].groupby('wsi')['label'].apply(max))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s][ WARN:0@26.949] global loadsave.cpp:244 findDecoder imread_('./patch_dataset_4096_512/0c7d6e0e07621b5582117e9977327b4c_2.png'): can't open/read file: check file path/integrity\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_ft \u001b[39m=\u001b[39m train\u001b[39m.\u001b[39;49mtrain_model(model_ft, \n\u001b[1;32m      2\u001b[0m                              criterion_dic, \n\u001b[1;32m      3\u001b[0m                              optimizer, \n\u001b[1;32m      4\u001b[0m                              df, \n\u001b[1;32m      5\u001b[0m                              data_transforms\u001b[39m=\u001b[39;49mdata_transforms,\n\u001b[1;32m      6\u001b[0m                              alpha\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, \n\u001b[1;32m      7\u001b[0m                              beta\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m, \n\u001b[1;32m      8\u001b[0m                              gamma\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m, \n\u001b[1;32m      9\u001b[0m                              num_epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, \n\u001b[1;32m     10\u001b[0m                              fpath\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtrained/checkpoint.pt\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     11\u001b[0m                              topk\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m/workspace/C2C/C2C/train.py:47\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion_dic, optimizer, df, data_transforms, alpha, beta, gamma, num_cluster, num_img_per_cluster, num_epochs, fpath, topk)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m \u001b[39m*\u001b[39m \u001b[39m10\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[39m# Run Clustering\u001b[39;00m\n\u001b[1;32m     46\u001b[0m train_images, train_images_cluster, valid_images, valid_images_cluster \u001b[39m=\u001b[39m \\\n\u001b[0;32m---> 47\u001b[0m                     run_clustering(train_images, valid_images, model, data_transforms\u001b[39m=\u001b[39;49mdata_transforms,\n\u001b[1;32m     48\u001b[0m                                   num_cluster\u001b[39m=\u001b[39;49mnum_cluster, topk\u001b[39m=\u001b[39;49mtopk)    \n\u001b[1;32m     50\u001b[0m \u001b[39m# Using mutual information to track cluster assignment change\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39mif\u001b[39;00m epoch\u001b[39m>\u001b[39m\u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/workspace/C2C/C2C/cluster.py:102\u001b[0m, in \u001b[0;36mrun_clustering\u001b[0;34m(train_img_dic, valid_img_dic, model_base, data_transforms, num_cluster, for_validation, topk)\u001b[0m\n\u001b[1;32m     98\u001b[0m tdl \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(td, batch_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    100\u001b[0m \u001b[39mif\u001b[39;00m topk:\n\u001b[1;32m    101\u001b[0m     \u001b[39m# Use patch classifier to identify most probable diseased patches\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     img_rep, path_list \u001b[39m=\u001b[39m select_topk(tdl, enc)\n\u001b[1;32m    103\u001b[0m     cluster \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones(\u001b[39mlen\u001b[39m(path_list))\n\u001b[1;32m    104\u001b[0m     \u001b[39m# MAX NUM PATCHES = 64 HARDCODE\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/C2C/C2C/cluster.py:61\u001b[0m, in \u001b[0;36mselect_topk\u001b[0;34m(dl, enc)\u001b[0m\n\u001b[1;32m     59\u001b[0m img_rep \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([])\n\u001b[1;32m     60\u001b[0m path_list \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 61\u001b[0m \u001b[39mfor\u001b[39;00m i, (input_image, input_image_path) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dl):\n\u001b[1;32m     62\u001b[0m     path_list \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(input_image_path)\n\u001b[1;32m     63\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(img_rep):\n",
      "File \u001b[0;32m/opt/conda/envs/py117/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/envs/py117/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/envs/py117/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/envs/py117/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/workspace/C2C/C2C/dataloader.py:22\u001b[0m, in \u001b[0;36mWSIDataloader.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m     21\u001b[0m     im_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_images[idx]\n\u001b[0;32m---> 22\u001b[0m     im \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcvtColor(cv2\u001b[39m.\u001b[39;49mimread(im_path), cv2\u001b[39m.\u001b[39;49mCOLOR_BGR2RGB)\n\u001b[1;32m     23\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform:\n\u001b[1;32m     24\u001b[0m         im \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(image\u001b[39m=\u001b[39mim)[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m]            \n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "model_ft = train.train_model(model_ft, \n",
    "                             criterion_dic, \n",
    "                             optimizer, \n",
    "                             df, \n",
    "                             data_transforms=data_transforms,\n",
    "                             alpha=1, \n",
    "                             beta=0.01, \n",
    "                             gamma=0.01, \n",
    "                             num_epochs=1, \n",
    "                             fpath='trained/checkpoint.pt',\n",
    "                             topk=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from C2C.utils import *\n",
    "\n",
    "ckp_path = \"trained/checkpoint.pt\"\n",
    "model_ft, optimizer = load_ckp(ckp_path, model_ft, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PATH = 'data/11-3-2021 celiac_normal_test_split.csv'\n",
    "df_test = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [03:37<00:00,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.7701149425287356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred_df = eval_test(model_ft, df_test, data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py117",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
